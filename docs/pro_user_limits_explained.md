# Sistema de LÃ­mites: Usuarios Free vs Pro

## Resumen Ejecutivo

El sistema utiliza dos estrategias diferentes para controlar costos segÃºn el tipo de usuario:

| Usuario | LÃ­mite por Hilo | Mensajes al LLM | Costo por Mensaje |
|---------|-----------------|-----------------|-------------------|
| **Free** | 50 mensajes | Ãšltimos 20 | Variable (debe contar) |
| **Pro** | âˆž Infinito | Ãšltimos 20 | Constante |

---

## Â¿Por quÃ© Free tiene lÃ­mite y Pro no?

### El Problema del Costo

El costo de cada mensaje **no depende de cuÃ¡ntos mensajes lleva el usuario en total**, sino de **cuÃ¡ntos tokens envÃ­as al LLM en cada request**.

```
Mensaje #1:   EnvÃ­as 1 mensaje   â†’ $0.01
Mensaje #50:  EnvÃ­as 50 mensajes â†’ $0.50  â† Â¡50x mÃ¡s caro!
Mensaje #100: EnvÃ­as 100 mensajes â†’ $1.00 â† Hemorragia de tokens
```

### La SoluciÃ³n: Rolling Window

Aplicamos una **ventana deslizante de 20 mensajes**. Sin importar cuÃ¡ntos mensajes lleve el hilo, siempre enviamos solo los Ãºltimos 20 al LLM:

```
Mensaje #1:    EnvÃ­as 1 mensaje   â†’ $0.01
Mensaje #50:   EnvÃ­as 20 mensajes â†’ $0.20
Mensaje #5000: EnvÃ­as 20 mensajes â†’ $0.20  â† Costo plano
```

---

## LÃ³gica por Tipo de Usuario

### Usuario Free (Modo AuditorÃ­a)

```python
fetch_limit = max_history_turns  # 50
```

**Â¿Por quÃ© traemos 50?** Porque necesitamos **contar** cuÃ¡ntos mensajes lleva el hilo para decidir si bloquearlo.

- Si solo traemos 20, `len(history)` siempre serÃ­a â‰¤ 20
- La condiciÃ³n `if len(history) >= 50` nunca se cumplirÃ­a
- El usuario Free tendrÃ­a chat infinito (bug)

**Flujo:**
1. Fetch de 50 mensajes
2. Â¿`len(history) >= 50`? â†’ Bloquear con mensaje de lÃ­mite
3. Si no, aplicar rolling window (Ãºltimos 20) y responder

### Usuario Pro (Modo Eficiencia)

```python
fetch_limit = ROLLING_WINDOW_SIZE  # 20
```

**Â¿Por quÃ© solo 20?** Porque Pro **no tiene lÃ­mite por hilo**. No necesitas contar nada, solo necesitas los Ãºltimos 20 para el contexto del LLM.

**Flujo:**
1. Fetch de 20 mensajes (el mÃ­nimo necesario)
2. Enviar al LLM y responder
3. No hay validaciÃ³n de lÃ­mite

---

## Â¿Por quÃ© Pro tiene hilos infinitos?

### Argumento Financiero

Con rolling window, el costo es **constante** sin importar la longitud del hilo:

| Mensaje # | Tokens enviados | Costo |
|-----------|-----------------|-------|
| 1 | ~500 | $0.01 |
| 100 | ~2000 (20 msgs) | $0.04 |
| 5,000 | ~2000 (20 msgs) | $0.04 |

**No hay razÃ³n financiera para limitar a un usuario que pagÃ³.**

### Argumento de Experiencia

El usuario Pro pagÃ³ por una experiencia **sin barreras**. Interrumpir su conversaciÃ³n en el mensaje 200 cuando el costo del mensaje 5000 es idÃ©ntico serÃ­a artificialmente restrictivo.

---

## ConfiguraciÃ³n

```json
{
    "MAX_HISTORY_TURNS": 50,      // LÃ­mite para usuarios Free
    "MAX_HISTORY_TURNS_PRO": 20   // Rolling window (no es un lÃ­mite)
}
```

> **Nota sobre nomenclatura:** `MAX_HISTORY_TURNS_PRO` es tÃ©cnicamente el tamaÃ±o del rolling window, no un "lÃ­mite". El nombre puede ser confuso pero la funcionalidad es correcta.

---

## CÃ³digo Relevante

```python
is_pro = self.user_service.is_user_pro(event.sender_id)
max_history_turns = self.user_service.get_user_max_history_turns(event.sender_id)

ROLLING_WINDOW_SIZE = 20

# Pro: solo trae lo necesario para el LLM
# Free: trae hasta el lÃ­mite para poder contarlo
fetch_limit = ROLLING_WINDOW_SIZE if is_pro else max_history_turns

history = await self.__build_reply_history(event, fetch_limit)

# Solo Free tiene lÃ­mite por hilo
if not is_pro and len(history) >= max_history_turns:
    await event.reply("LÃ­mite alcanzado...")
    return

# Ambos usan rolling window para el contexto del LLM
context_for_dspy = history[-ROLLING_WINDOW_SIZE:]
```

---

## TL;DR

- **Free:** Traemos 50 para contar â†’ Bloqueamos en 50 â†’ Enviamos 20 al LLM
- **Pro:** Traemos 20 â†’ No bloqueamos nunca â†’ Enviamos 20 al LLM
- **Costo Pro constante:** El mensaje #5000 cuesta igual que el #1
- **El cÃ³digo estÃ¡ correcto.** ðŸš€
